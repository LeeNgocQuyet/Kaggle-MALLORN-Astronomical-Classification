{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89959e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Reset working (Kaggle-style)\n",
    "!rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e99fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & config\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629723ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Core feature-extraction engine\n",
    "def extract_features_from_split(csv_path):\n",
    "    if not os.path.exists(csv_path):\n",
    "        return None\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # compute SNR if available\n",
    "    if 'Flux_err' in df.columns:\n",
    "        df['snr'] = df['Flux'] / (df['Flux_err'] + 1e-6)\n",
    "    # basic stats + skew\n",
    "    aggs = df.groupby(['object_id','Filter'])['Flux'].agg(['max','min','mean','std',skew]).unstack()\n",
    "    aggs.columns = [f'{stat}_{filt}' for stat,filt in aggs.columns]\n",
    "    # color features (example g - r)\n",
    "    if 'max_g' in aggs.columns and 'max_r' in aggs.columns:\n",
    "        aggs['color_g_r'] = aggs['max_g'] - aggs['max_r']\n",
    "    if 'max_u' in aggs.columns and 'max_z' in aggs.columns:\n",
    "        aggs['color_u_z'] = aggs['max_u'] - aggs['max_z']\n",
    "    # amplitude per filter\n",
    "    filters = df['Filter'].unique()\n",
    "    for f in filters:\n",
    "        if f'max_{f}' in aggs.columns and f'min_{f}' in aggs.columns:\n",
    "            aggs[f'amp_{f}'] = aggs[f'max_{f}'] - aggs[f'min_{f}']\n",
    "    counts = df.groupby('object_id').size().to_frame('n_obs')\n",
    "    features = aggs.merge(counts, left_index=True, right_index=True)\n",
    "    return features\n",
    "\n",
    "def load_all_splits(base_path, mode='train'):\n",
    "    all_features = []\n",
    "    print(f\"Bắt đầu xử lý dữ liệu {mode} từ 20 splits...\")\n",
    "    for i in range(1,21):\n",
    "        split_name = f'split_{i:02d}'\n",
    "        file_name = f'{mode}_full_lightcurves.csv'\n",
    "        full_path = os.path.join(base_path, split_name, file_name)\n",
    "        print(f\"Processing {split_name}...\", end='\n",
    "')\n",
    "        feats = extract_features_from_split(full_path)\n",
    "        if feats is not None:\n",
    "            all_features.append(feats)\n",
    "        del feats\n",
    "        gc.collect()\n",
    "    print(f\"\n",
    "Đã xử lý xong {mode}!\")\n",
    "    return pd.concat(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Run feature extraction (example base path)\n",
    "BASE_PATH = '/kaggle/input/mallorn-dataset'\n",
    "# train_lc_features = load_all_splits(BASE_PATH, mode='train')\n",
    "# test_lc_features = load_all_splits(BASE_PATH, mode='test')\n",
    "# print('Train features shape:', train_lc_features.shape)\n",
    "# print('Test features shape:', test_lc_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocessing: select features, scale, SMOTE (example)\n",
    "# drop_cols = ['object_id','SpecType','English Translation','split','target','Z_err']\n",
    "# feature_cols = [c for c in full_train.columns if c not in drop_cols]\n",
    "# X = full_train[feature_cols]\n",
    "# y = full_train['target']\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aed029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model training: SVM baseline (GridSearch example)\n",
    "# svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "# param_grid = {'C':[1,10,100], 'gamma':['scale',0.1,0.01]}\n",
    "# grid = GridSearchCV(svm, param_grid, cv=3, scoring='f1', verbose=2, n_jobs=-1)\n",
    "# grid.fit(X_train, y_train)\n",
    "# best_model = grid.best_estimator_\n",
    "# y_pred_val = best_model.predict(X_val)\n",
    "# print('Validation F1:', f1_score(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. XGBoost GPU example (commented; requires GPU & xgboost installed)\n",
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier(tree_method='hist', device='cuda', eval_metric='logloss', random_state=42, use_label_encoder=False)\n",
    "# # param grid / randomized search snippet here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fccc65",
   "metadata": {},
   "source": [
    "---\n",
    "Notes:\n",
    "- Cells that run long (feature extraction, grid search) are left commented so the notebook stored in repo has no heavy outputs.\n",
    "- To run: uncomment required cells and ensure `BASE_PATH` points to your dataset (`data/raw` or Kaggle input`)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
