{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Experiment 06: Bagging SVM with RobustScaler\n",
                "\n",
                "## Overview\n",
                "This notebook introduces ensemble learning to stabilize the SVM model.\n",
                "- **Feature Extraction**: Includes SNR and basic statistics (Max, Min, Mean, Std, Skew).\n",
                "- **Preprocessing**: Median Imputation + RobustScaler (better for outliers) + SMOTE.\n",
                "- **Model**: BaggingClassifier with SVC base estimator.\n",
                "- **Optimization**: RandomizedSearchCV for Bagging SVM.\n",
                "- **Refinement**: Threshold Tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Import & Config\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import os\n",
                "import gc\n",
                "import warnings\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
                "from sklearn.preprocessing import RobustScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.feature_selection import SelectKBest, f_classif\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.ensemble import BaggingClassifier\n",
                "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_curve\n",
                "\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from imblearn.pipeline import Pipeline as ImbPipeline\n",
                "\n",
                "%matplotlib inline\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Feature Extraction\n",
                "from scipy.stats import skew\n",
                "\n",
                "def extract_features_from_split(csv_path):\n",
                "    if not os.path.exists(csv_path): return None\n",
                "    df = pd.read_csv(csv_path)\n",
                "    \n",
                "    # 1. TÍNH SNR (Tín hiệu trên nhiễu)\n",
                "    df['snr'] = df['Flux'] / (df['Flux_err'] + 1e-6)\n",
                "    \n",
                "    # 2. Thống kê cơ bản\n",
                "    aggs = df.groupby(['object_id', 'Filter']).agg({\n",
                "        'Flux': ['max', 'min', 'mean', 'std', skew], # Skew rất quan trọng\n",
                "        'snr': ['max', 'mean']\n",
                "    }).unstack()\n",
                "    aggs.columns = [f'{col[0]}_{col[1]}_{col[2]}' for col in aggs.columns]\n",
                "    \n",
                "    # 3. Tính Màu & Biên độ (Vật lý)\n",
                "    if 'Flux_max_g' in aggs.columns and 'Flux_max_r' in aggs.columns:\n",
                "        aggs['color_g_r'] = aggs['Flux_max_g'] - aggs['Flux_max_r']\n",
                "        # Thêm tỷ lệ (Ratio) - SVM thích cái này hơn hiệu số\n",
                "        aggs['ratio_g_r'] = aggs['Flux_max_g'] / (aggs['Flux_max_r'] + 1)\n",
                "\n",
                "    filters = df['Filter'].unique()\n",
                "    for f in filters:\n",
                "        if f'Flux_max_{f}' in aggs.columns and f'Flux_min_{f}' in aggs.columns:\n",
                "            aggs[f'amp_{f}'] = aggs[f'Flux_max_{f}'] - aggs[f'Flux_min_{f}']\n",
                "            \n",
                "    # 4. Số lượng quan sát\n",
                "    counts = df.groupby('object_id').size().to_frame('n_obs')\n",
                "    \n",
                "    # Merge lại\n",
                "    features = aggs.merge(counts, left_index=True, right_index=True)\n",
                "    return features\n",
                "\n",
                "# Hàm hỗ trợ load toàn bộ 20 splits\n",
                "def load_all_splits(base_path, mode='train'):\n",
                "    all_features = []\n",
                "    print(f\"Bắt đầu xử lý dữ liệu {mode} từ 20 splits...\")\n",
                "    \n",
                "    for i in range(1, 21):\n",
                "        split_name = f'split_{i:02d}' # Format 01, 02...\n",
                "        file_name = f'{mode}_full_lightcurves.csv'\n",
                "        full_path = os.path.join(base_path, split_name, file_name)\n",
                "        \n",
                "        print(f\"Processing {split_name}...\", end='\\r')\n",
                "        \n",
                "        feats = extract_features_from_split(full_path)\n",
                "        if feats is not None:\n",
                "            all_features.append(feats)\n",
                "            \n",
                "        # Giải phóng bộ nhớ RAM\n",
                "        del feats\n",
                "        gc.collect()\n",
                "        \n",
                "    print(f\"\\nĐã xử lý xong {mode}!\")\n",
                "    # Gộp tất cả các split thành 1 DataFrame lớn\n",
                "    return pd.concat(all_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Load & Process Data\n",
                "BASE_PATH = 'data/raw'\n",
                "\n",
                "print(\"Loading Train features...\")\n",
                "train_lc_features = load_all_splits(BASE_PATH, mode='train')\n",
                "test_lc_features = load_all_splits(BASE_PATH, mode='test')\n",
                "\n",
                "print(\"Loading Log...\")\n",
                "train_log = pd.read_csv(os.path.join(BASE_PATH, 'train_log.csv'))\n",
                "test_log = pd.read_csv(os.path.join(BASE_PATH, 'test_log.csv'))\n",
                "\n",
                "full_train = train_log.merge(train_lc_features, on='object_id', how='left')\n",
                "full_test = test_log.merge(test_lc_features, on='object_id', how='left')\n",
                "\n",
                "full_train.fillna(0, inplace=True)\n",
                "full_test.fillna(0, inplace=True)\n",
                "\n",
                "display(full_train.head(3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Prepare Data\n",
                "drop_cols = ['object_id', 'SpecType', 'English Translation', 'split', 'target', 'Z_err']\n",
                "feature_cols = [c for c in full_train.columns if c not in drop_cols]\n",
                "\n",
                "X = full_train[feature_cols]\n",
                "y = full_train['target']\n",
                "X_test_sub = full_test[feature_cols]\n",
                "\n",
                "# Split\n",
                "X_train_org, X_val_org, y_train_org, y_val_org = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"TDE in Val: {sum(y_val_org==1)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Pipeline & RandomizedSearchCV\n",
                "# Base SVM\n",
                "svc_base = SVC(\n",
                "    kernel='rbf', \n",
                "    probability=True,       \n",
                "    class_weight='balanced', \n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "svm_pipeline = ImbPipeline([\n",
                "    ('imputer', SimpleImputer(strategy='median')),\n",
                "    ('scaler', RobustScaler()),\n",
                "    ('smote', SMOTE(random_state=42, k_neighbors=7)),\n",
                "    ('select', SelectKBest(score_func=f_classif)),    \n",
                "    ('bagging', BaggingClassifier(\n",
                "        estimator=svc_base,\n",
                "        n_estimators=10,\n",
                "        max_samples=0.8,\n",
                "        bootstrap=True,\n",
                "        random_state=42,\n",
                "        n_jobs=-1\n",
                "    )) \n",
                "])\n",
                "\n",
                "param_grid = {\n",
                "    'select__k': [20, 30, 'all'],\n",
                "    'bagging__estimator__C': [10, 50, 100],\n",
                "    'bagging__estimator__gamma': ['scale', 0.1],\n",
                "    'smote__sampling_strategy': [0.5, 0.8]\n",
                "}\n",
                "\n",
                "print(\"Running RandomizedSearchCV...\")\n",
                "search = RandomizedSearchCV(\n",
                "    svm_pipeline, \n",
                "    param_grid, \n",
                "    n_iter=10,\n",
                "    cv=3, \n",
                "    scoring='f1', \n",
                "    verbose=2, \n",
                "    random_state=42,\n",
                "    n_jobs=1\n",
                ")\n",
                "\n",
                "search.fit(X_train_org, y_train_org)\n",
                "best_model = search.best_estimator_\n",
                "\n",
                "print(\"\\nBest params:\", search.best_params_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Threshold Tuning\n",
                "y_val_prob = best_model.predict_proba(X_val_org)[:, 1]\n",
                "\n",
                "precisions, recalls, thresholds = precision_recall_curve(y_val_org, y_val_prob)\n",
                "f1_scores = np.divide(2 * precisions * recalls, precisions + recalls, out=np.zeros_like(precisions), where=(precisions + recalls)!=0)\n",
                "\n",
                "best_idx = np.argmax(f1_scores)\n",
                "best_threshold = thresholds[best_idx]\n",
                "\n",
                "print(f\"Best Threshold: {best_threshold:.4f}\")\n",
                "print(f\"Max Validation F1: {f1_scores[best_idx]:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Submission\n",
                "y_test_prob = best_model.predict_proba(X_test_sub)[:, 1]\n",
                "final_predictions = (y_test_prob >= best_threshold).astype(int)\n",
                "\n",
                "submission = pd.DataFrame({\n",
                "    'object_id': full_test['object_id'],\n",
                "    'prediction': final_predictions\n",
                "})\n",
                "\n",
                "print(submission['prediction'].value_counts())\n",
                "submission.to_csv('submission_svm_bagging_robust.csv', index=False)\n",
                "print(\"Done.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}