{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Experiment 03: Basic SVM Pipeline (No Threshold Tuning)\n",
                "\n",
                "## Overview\n",
                "This notebook implements the SVM pipeline without the threshold tuning step, using the default 0.5 decision boundary.\n",
                "- **Core**: Feature Extraction (User Engine).\n",
                "- **Preprocessing**: StandardScaler + SMOTE.\n",
                "- **Model**: SVC (RBF kernel) + GridSearch.\n",
                "- **Evaluation**: Standard F1 Score (Default Threshold)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Import & Config\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "import gc\n",
                "import warnings\n",
                "\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
                "from sklearn.impute import SimpleImputer\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Custom module\n",
                "from src.data_processing import load_all_splits\n",
                "\n",
                "%matplotlib inline\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Feature Extraction\n",
                "BASE_PATH = 'data/raw'\n",
                "\n",
                "print(\"Loading Train features...\")\n",
                "train_lc_features = load_all_splits(BASE_PATH, mode='train')\n",
                "\n",
                "print(\"Loading Test features...\")\n",
                "test_lc_features = load_all_splits(BASE_PATH, mode='test')\n",
                "\n",
                "print(\"Shape Train:\", train_lc_features.shape)\n",
                "print(\"Shape Test:\", test_lc_features.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Merge Metadata\n",
                "train_log = pd.read_csv(os.path.join(BASE_PATH, 'train_log.csv'))\n",
                "test_log = pd.read_csv(os.path.join(BASE_PATH, 'test_log.csv'))\n",
                "\n",
                "full_train = train_log.merge(train_lc_features, on='object_id', how='left')\n",
                "full_test = test_log.merge(test_lc_features, on='object_id', how='left')\n",
                "\n",
                "full_train.fillna(0, inplace=True)\n",
                "full_test.fillna(0, inplace=True)\n",
                "\n",
                "display(full_train.head(3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Preprocessing (Scale & SMOTE)\n",
                "drop_cols = ['object_id', 'SpecType', 'English Translation', 'split', 'target', 'Z_err']\n",
                "feature_cols = [c for c in full_train.columns if c not in drop_cols]\n",
                "\n",
                "print(f\"Using {len(feature_cols)} features.\")\n",
                "\n",
                "X = full_train[feature_cols]\n",
                "y = full_train['target']\n",
                "X_test_final = full_test[feature_cols]\n",
                "\n",
                "# Scaling\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "X_test_scaled = scaler.transform(X_test_final)\n",
                "\n",
                "# SMOTE\n",
                "print(f\"Original TDE: {sum(y==1)}\")\n",
                "smote = SMOTE(random_state=42)\n",
                "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
                "print(f\"After SMOTE TDE: {sum(y_resampled==1)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Training & Grid Search\n",
                "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
                "\n",
                "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
                "\n",
                "param_grid = {\n",
                "    'C': [1, 10, 100],\n",
                "    'gamma': ['scale', 0.1, 0.01]\n",
                "}\n",
                "\n",
                "print(\"Starting Grid Search...\")\n",
                "grid = GridSearchCV(svm, param_grid, cv=3, scoring='f1', verbose=2, n_jobs=-1)\n",
                "grid.fit(X_train, y_train)\n",
                "\n",
                "best_model = grid.best_estimator_\n",
                "print(\"Best params:\", grid.best_params_)\n",
                "\n",
                "# Validation Eval (Using predict directly, implying 0.5 threshold)\n",
                "y_pred_val = best_model.predict(X_val)\n",
                "print(\"Val F1:\", f1_score(y_val, y_pred_val))\n",
                "print(classification_report(y_val, y_pred_val))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Threshold Tuning (Commented Out as per User request)\n",
                "# from sklearn.metrics import precision_recall_curve\n",
                "\n",
                "# # Dự đoán xác suất thay vì nhãn (cần set probability=True khi tạo SVM)\n",
                "# y_val_prob = best_model.predict_proba(X_val)[:, 1]\n",
                "\n",
                "# # Tìm ngưỡng tối ưu cho F1\n",
                "# precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_prob)\n",
                "# f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
                "# best_threshold = thresholds[np.argmax(f1_scores)]\n",
                "\n",
                "# print(f\"Ngưỡng tối ưu: {best_threshold}\")\n",
                "# print(f\"F1 Score tốt nhất: {np.max(f1_scores)}\")\n",
                "\n",
                "# # Áp dụng ngưỡng này cho tập Test\n",
                "# y_test_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
                "# final_predictions = (y_test_prob >= best_threshold).astype(int)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Submission\n",
                "# Using predict directly (0.5 threshold)\n",
                "final_predictions = best_model.predict(X_test_scaled)\n",
                "\n",
                "submission = pd.DataFrame({\n",
                "    'object_id': full_test['object_id'],\n",
                "    'prediction': final_predictions\n",
                "})\n",
                "\n",
                "print(submission['prediction'].value_counts())\n",
                "submission.to_csv('submission_svm_improved.csv', index=False)\n",
                "print(\"Done.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}