{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Experiment 06: SVM New Features (Standard GridSearch)\n",
                "\n",
                "## Overview\n",
                "This experiment introduces SNR, Duration, and Ratio features.\n",
                "- **Feature Extraction**: Enhanced (SNR, Duration, Ratio).\n",
                "- **Pipeline**: Imputer -> Scaler -> SMOTE -> SelectKBest -> SVC.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Import & Config\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import os\n",
                "import gc\n",
                "import warnings\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.feature_selection import SelectKBest, f_classif\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
                "\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from imblearn.pipeline import Pipeline as ImbPipeline\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Feature Extraction (Enhanced)\n",
                "from scipy.stats import skew, kurtosis\n",
                "\n",
                "def extract_features_from_split(csv_path):\n",
                "    if not os.path.exists(csv_path): return None\n",
                "    df = pd.read_csv(csv_path)\n",
                "    \n",
                "    # 1. TÍNH TOÁN CÁC ĐẶC TRƯNG CƠ BẢN (Như cũ)\n",
                "    # Thêm 'Flux_err' vào để tính SNR\n",
                "    df['snr'] = df['Flux'] / (df['Flux_err'] + 1e-6)\n",
                "    \n",
                "    aggs = df.groupby(['object_id', 'Filter']).agg({\n",
                "        'Flux': ['max', 'min', 'mean', 'std', skew],\n",
                "        'snr': ['max', 'mean']\n",
                "    }).unstack()\n",
                "    aggs.columns = [f'{col[0]}_{col[1]}_{col[2]}' for col in aggs.columns]\n",
                "    \n",
                "    # --- 2. TÍNH ĐẶC TRƯNG THỜI GIAN (MỚI) ---\n",
                "    time_aggs = df.groupby('object_id')['Time (MJD)'].agg(['min', 'max'])\n",
                "    time_aggs['duration'] = time_aggs['max'] - time_aggs['min']\n",
                "    \n",
                "    # --- 3. TÍNH MÀU & BIÊN ĐỘ (Như cũ) ---\n",
                "    if 'Flux_max_g' in aggs.columns and 'Flux_max_r' in aggs.columns:\n",
                "        aggs['color_g_r'] = aggs['Flux_max_g'] - aggs['Flux_max_r']\n",
                "        aggs['ratio_g_r'] = aggs['Flux_max_g'] / (aggs['Flux_max_r'] + 1)\n",
                "\n",
                "    filters = df['Filter'].unique()\n",
                "    for f in filters:\n",
                "        if f'Flux_max_{f}' in aggs.columns and f'Flux_min_{f}' in aggs.columns:\n",
                "            aggs[f'amp_{f}'] = aggs[f'Flux_max_{f}'] - aggs[f'Flux_min_{f}']\n",
                "            \n",
                "    # --- 4. MERGE ---\n",
                "    counts = df.groupby('object_id').size().to_frame('n_obs')\n",
                "    \n",
                "    features = aggs.merge(counts, left_index=True, right_index=True)\n",
                "    features = features.merge(time_aggs[['duration']], left_index=True, right_index=True)\n",
                "    \n",
                "    return features\n",
                "\n",
                "# Hàm hỗ trợ load toàn bộ 20 splits\n",
                "def load_all_splits(base_path, mode='train'):\n",
                "    all_features = []\n",
                "    print(f\"Bắt đầu xử lý dữ liệu {mode} từ 20 splits...\")\n",
                "    \n",
                "    for i in range(1, 21):\n",
                "        split_name = f'split_{i:02d}' \n",
                "        file_name = f'{mode}_full_lightcurves.csv'\n",
                "        full_path = os.path.join(base_path, split_name, file_name)\n",
                "        print(f\"Processing {split_name}...\", end='\\r')\n",
                "        feats = extract_features_from_split(full_path)\n",
                "        if feats is not None:\n",
                "            all_features.append(feats)\n",
                "        del feats\n",
                "        gc.collect()\n",
                "    print(f\"\\nĐã xử lý xong {mode}!\")\n",
                "    return pd.concat(all_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Load & Prepare Data\n",
                "BASE_PATH = 'data/raw'\n",
                "train_lc_features = load_all_splits(BASE_PATH, mode='train')\n",
                "test_lc_features = load_all_splits(BASE_PATH, mode='test')\n",
                "train_log = pd.read_csv(os.path.join(BASE_PATH, 'train_log.csv'))\n",
                "test_log = pd.read_csv(os.path.join(BASE_PATH, 'test_log.csv'))\n",
                "full_train = train_log.merge(train_lc_features, on='object_id', how='left')\n",
                "full_test = test_log.merge(test_lc_features, on='object_id', how='left')\n",
                "full_train.fillna(0, inplace=True)\n",
                "full_test.fillna(0, inplace=True)\n",
                "\n",
                "drop_cols = ['object_id', 'SpecType', 'English Translation', 'split', 'target', 'Z_err']\n",
                "feature_cols = [c for c in full_train.columns if c not in drop_cols]\n",
                "X = full_train[feature_cols]\n",
                "y = full_train['target']\n",
                "X_test_sub = full_test[feature_cols]\n",
                "\n",
                "X_train_org, X_val_org, y_train_org, y_val_org = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Pipeline & GridSearch\n",
                "svm_pipeline = ImbPipeline([\n",
                "    ('imputer', SimpleImputer(strategy='mean')),\n",
                "    ('scaler', StandardScaler()),\n",
                "    ('smote', SMOTE(random_state=42, k_neighbors=5)),\n",
                "    ('select', SelectKBest(score_func=f_classif)),\n",
                "    ('svm', SVC(probability=True, kernel='rbf', class_weight='balanced', random_state=42))\n",
                "])\n",
                "\n",
                "param_grid = {\n",
                "    'select__k': [20, 30, 'all'],\n",
                "    'svm__C': [1, 10, 100],\n",
                "    'svm__gamma': ['scale', 0.1],\n",
                "    'smote__sampling_strategy': [0.5, 1.0]\n",
                "}\n",
                "\n",
                "print(\"Running GridSearch...\")\n",
                "grid = GridSearchCV(svm_pipeline, param_grid, cv=3, scoring='f1', verbose=2, n_jobs=-1)\n",
                "grid.fit(X_train_org, y_train_org)\n",
                "\n",
                "print(\"Best params:\", grid.best_params_)\n",
                "best_model = grid.best_estimator_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Evaluation\n",
                "y_pred_val = best_model.predict(X_val_org)\n",
                "print(\"Validation F1:\", f1_score(y_val_org, y_pred_val))\n",
                "print(classification_report(y_val_org, y_pred_val))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}